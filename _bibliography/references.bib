@preamble{ " \newcommand{\noop}[1]{} " }
@inproceedings{sammons2009relation,
  title = {Relation alignment for textual entailment recognition},
  author = {Sammons, Mark and Vydiswaran, V G Vinod and Vieira, Tim and
      Johri, Nikhil and Chang, Ming-Wei and Goldwasser, Dan and
      Srikumar, Vivek and Kundu, Gourab and Tu, Yuancheng and Small, Kevin and
      Rule, Joshua and Do, Quang and Roth, Dan},
  booktitle = {Proceedings of the Textual Alignment Conference},
  year = {2009},
  url = {./files/sammons2009relation.pdf},
  abstract = {We present an approach to textual entailment recognition, in which inference is based on a shallow semantic representation of relations (predicates and their arguments) in the text and hypothesis of the entailment pair, and in which specialized knowledge is encapsulated in modular components with very simple interfaces. We propose an architecture designed to integrate different, unscaled Natural Language Processing resources, and demonstrate an alignment-based method for combining them. We clarify the purpose of alignment in the RTE task, identifying two distinct alignment models, each of which leads to a different type of entailment system. We identify desirable properties of alignment, and use this to inform our implementation of an alignment component. We evaluate the resulting system on the RTE5 data set, and use an ablation study to assess the conformance of our alignment approach with these desired characteristics.},
  author+an = {11=highlight},
  keywords = {proceedings},
  index = {1}
}
@inproceedings{glezer2013novel,
  title = {Novel word learning selectively sharpens orthographic representations in the {{VWFA}}},
  author = {Glezer, Laurie S. and Kim, Judy S. and Rule, Joshua and Jiang, Xiong and Riesenhuber, Maximilian},
  year = {2013},
  booktitle = {Neuroscience 2013 Abstracts},
  note = {Poster and abstract},
  url = {./files/glezer2013novel.abstract.pdf},
  author+an = {3=highlight},
  keywords = {misc},
  index = {2}
}
@inproceedings{dechter2014unsupervised,
  title = {Unsupervised learning of probabilistic programs with {{Latent Predicate Networks}}},
  author = {Dechter, Eyal and Rule, Joshua and Tenenbaum, Joshua B.},
  year = {2014},
  booktitle = {Proceedings of the NIPS Workshop on Probabilistic Programming},
  note = {Poster and abstract},
  url = {./files/dechter2014unsupervised.abstract.pdf},
  keywords = {misc},
  author+an = {2=highlight},
  index = {3}
}
@inproceedings{dechter2015latent,
  title = {{{Latent Predicate Networks}}: {{Concept}} learning with probabilistic context-sensitive grammars},
  author = {Dechter, Eyal and Rule, Joshua and Tenenbaum, Joshua B},
  year = {2015},
  booktitle={Proceedings of the  AAAI Spring Symposium Series},
  note = {Poster and abstract},
  abstract = {For humans, learning abstract concepts and learning language go hand in hand: we acquire abstract knowledge primarily through linguistic experience, and acquiring abstract concepts is a crucial step in learning the meanings of linguistic expressions. Number knowledge is a case in point: we largely acquire concepts such as seventy-three through linguistic means, and we can only know what the sentence ``seventy-three is more than twice as big as thirty-one'' means if we can grasp the meanings of its component number words. How do we begin to solve this problem? One approach is to estimate the distribution from which sentences are drawn, and, in doing so, infer the latent concepts and relationships that best explain those sentences. We present early work on a learning framework called Latent Predicate Networks (LPNs) which learns concepts by inferring the parameters of probabilistic context-sensitive grammars over sentences. We show that for a small fragment of sentences expressing relationships between English number words, we can use hierarchical Bayesian inference to learn grammars that can answer simple queries about previously unseen relationships within this domain. These generalizations demonstrate LPNs' promise as a tool for learning and representing conceptual knowledge in language.},
  url = {./files/dechter2015latent.abstract.pdf},
  author+an = {2=highlight},
  keywords = {misc},
  index = {4}
}
@article{glezer2015adding,
  title = {Adding words to the brain's visual dictionary: {{Novel}} word learning selectively sharpens orthographic representations in the {{VWFA}}},
  author = {Glezer, L. S. and Kim, J. and Rule, Joshua and Jiang, X. and Riesenhuber, M.},
  year = {2015},
  journaltitle = {Journal of Neuroscience},
  volume = {35},
  number = {12},
  url = {./files/glezer2015adding.pdf},
  author+an = {3=highlight},
  keywords = {journal},
  index = {5}
}
@inproceedings{rule2015representing,
  title = {Representing and learning a large system of number concepts with {{Latent Predicate Networks}}},
  booktitle = {Proceedings of the {{Cognitive Science Society}}},
  author = {Rule, Joshua and Dechter, Eyal and Tenenbaum, Joshua B},
  year = {2015},
  url = {./files/rule2015representing.pdf},
  author+an = {1=highlight},
  keywords = {proceedings},
  index = {6}
}
@inproceedings{rule2018learning,
  title = {Learning list concepts through program induction},
  booktitle = {Proceedings of the {{Cognitive Science Society}}},
  author = {Rule, Joshua and Schulz, Eric and Piantadosi, Steven T. and Tenenbaum, Joshua B.},
  year = {2018},
  abstract = {Humans master complex systems of interrelated concepts like mathematics and natural language. Previous work suggests learning these systems relies on iteratively and directly revising a language-like conceptual representation. We introduce and assess a novel concept learning paradigm called Martha's Magical Machines that captures complex relationships between concepts. We model human concept learning in this paradigm as a search in the space of term rewriting systems, previously developed as an abstract model of computation. Our model accurately predicts that participants learn some transformations more easily than others and that they learn harder concepts more easily using a bootstrapping curriculum focused on their compositional parts. Our results suggest that term rewriting systems may be a useful model of human conceptual representations.},
  url = {./files/rule2018learning.pdf},
  author+an = {1=highlight},
  keywords = {proceedings},
  index = {7}
}
@inproceedings{rule2019learning,
  title = {Learning a novel rule-based conceptual system},
  author = {Rule, Joshua S and Piantadosi, Steven T and Tenenbaum, Joshua B},
  booktitle = {Proceedings of the {{Cognitive Science Society}}},
  year = {2019},
  abstract = {Humans have developed complex rule-based systems to explain and exploit the world around them. When a learner has already mastered a system's core dynamics\textemdash identifying its primitives and their interrelations\textemdash further learning can be effectively modeled as discovering useful compositions of these primitives. It nevertheless remains unclear how the dynamics themselves might initially be acquired. Composing primitives is no longer a viable strategy, as the primitives themselves are what must be explained. To explore this problem, we introduce and assess a novel concept learning paradigm in which participants use a two-alternative forced-choice task to learn an unfamiliar rule-based conceptual system: the MUI system (Hofstadter, 1980). We show that participants reliably learn this system given a few dozen examples of the system's rules, leaving open the mechanism by which novel conceptual systems are acquired but providing a useful paradigm for further study.},
  note = {Poster and abstract},
  url = {./files/rule2019learning.abstract.pdf},
  author+an = {1=highlight},
  keywords = {misc},
  index = {8}
}
@phdthesis{rule2020child,
  title = {The child as hacker: {{Building}} more human-like models of learning},
  author = {Rule, Joshua S},
  year = {2020},
  institution = {MIT},
  abstract = {Cognitive science faces a radical challenge in explaining the richness of human learning and cognitive development. This thesis proposes that developmental theories can address the challenge by adopting perspectives from computer science. Many of our best models treat learning as analogous to computer programming because symbolic programs provide the most compelling account of sophisticated mental representations. We specifically propose that learning from childhood onward is analogous to a style of programming called hacking\textemdash making code better along many dimensions through an open-ended and internally-motivated set of diverse values and activities. This thesis also develops a first attempt to formalize and assess the child as hacker view through an in-depth empirical study of human and machine concept learning. It introduces list functions as a domain for psychological investigation, demonstrating how they subsume many classic concept learning tasks while opening new avenues for exploring algorithmic thinking over complex structures. It also presents HL, a computational learning model whose representations, objectives, and mechanisms reflect core principles of hacking. Existing work on concept learning shows that learners both prefer simple explanations of data and find them easier to learn than complex ones. The child as hacker, by contrast, suggests that learners use mechanisms that dissociate hypothesis complexity and learning difficulty for certain problem classes. We thus conduct a large-scale experiment exploring list functions that vary widely in difficulty and algorithmic content to help identify structural sources of learning difficulty. We find that while description length alone predicts learning, predictions are much better when accounting for concepts' semantic features. These include the use of internal arguments, counting knowledge, case-based and recursive reasoning, and visibility\textemdash a measure we introduce to modify description length based on the complexity of inferring each symbol in a description. We further show that HL's hacker-like design uses these semantic features to better predict human performance than several alternative models of learning as programming. These results lay groundwork for a new generation of computational models and demonstrate how the child as hacker hypothesis can productively contribute to our understanding of learning.},
  url = {./files/rule2020child.pdf},
  keywords = {thesis},
  index = {9}
}
@article{rule2020child2,
  title = {The child as hacker},
  author = {Rule, Joshua S. and Piantadosi, Steven T. and Tenenbaum, Joshua B.},
  year = {2020},
  journaltitle = {Trends in Cognitive Sciences},
  url = {./files/rule2020child2.pdf},
  keywords = {journal},
  author+an = {1=highlight},
  index = {10}
}
@article{rule2021leveraging,
  title = {Leveraging prior concept learning improves ability to generalize from few examples in computational models of human object recognition},
  author = {Rule, Joshua S. and Riesenhuber, Maximilian},
  year = {2021},
  journaltitle = {Frontiers in Computational Neuroscience},
  url = {./files/rule2021leveraging.pdf},
  author+an = {1=highlight},
  keywords = {journal},
  index = {11}
}
@inproceedings{goddu2022learning,
  title = {Fun isn’t easy: {{C}}hildren optimize for difficulty when ``playing for fun'' vs. ``playing to win'' in a game design task},
  author = {Goddu, Mariel K and Rule, Joshua S and Bonawitz, Elizabeth and Gonik, Alison and Ullman, Tomer},
  year = {2022},
  booktitle = {{{Budapest CEU Conference on Cognitive Development}} Programs and Abstracts},
  note = {Talk and abstract},
  keywords = {misc},
  author+an = {2=highlight},
  index = {12}
}
@inproceedings{goddu2022learning2,
  title = {Fun isn’t easy: {{C}}hildren optimize for difficulty when ``playing for fun'' vs. ``playing to win'' in a game design task},
  author = {Goddu, Mariel K and Rule, Joshua S and Bonawitz, Elizabeth and Gonik, Alison and Ullman, Tomer},
  year = {2022},
  booktitle = {{{Cognitive Development Society}} Abstract Book},
  note = {Poster and abstract},
  keywords = {misc},
  author+an = {2=highlight},
  index = {13}
}
@inproceedings{goddu2022learning3,
  title = {Fun isn’t easy: {{C}}hildren optimize for difficulty when ``playing for fun'' vs. ``playing to win'' in a game design task},
  author = {Goddu, Mariel K and Rule, Joshua S and Bonawitz, Elizabeth and Gonik, Alison and Ullman, Tomer},
  year = {2022},
  booktitle = {{{Society for Research in Child Development’s Learning through Play and Imagination: Expanding Perspectives}}},
  note = {Poster and abstract},
  url = {./files/goddu2022learning3.abstract.pdf},
  keywords = {misc},
  author+an = {2=highlight},
  index = {14}
}
@inproceedings{rule2022learning,
  title = {Learning as programming: {{Efficient}} search in models of human concept learning},
  author = {Rule, Joshua S. and Piantadosi, Steven T. and Tenenbaum, Joshua B.},
  booktitle = {Proceedings of the {{Cognitive Science Society}}},
  year = {2022},
  note = {Talk and abstract},
  url = {./files/rule2022learning.abstract.pdf},
  keywords = {proceedings},
  author+an = {1=highlight},
  index = {15}
}
@article{srivastava2023beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adri{\`a} Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Johan Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlm{\"u}ller and Andrew M. Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karaka{\c{s}} and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bart{\l}omiej Bojanowski and Batuhan {\"O}zyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and Cesar Ferri and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Christopher Waites and Christian Voigt and Christopher D Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and C. Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Mosegu{\'\i} Gonz{\'a}lez and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodol{\`a} and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Mart{\'\i}nez-Plumed and Francesca Happ{\'e} and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germ{\'a}n Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Xinyue Wang and Gonzalo Jaimovitch-Lopez and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Francis Anthony Shevlin and Hinrich Schuetze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fern{\'a}ndez Fisac and James B Simon and James Koppel and James Zheng and James Zou and Jan Kocon and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and J{\"o}rg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh Dhole and Kevin Gimpel and Kevin Omondi and Kory Wallace Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros-Col{\'o}n and Luke Metz and L{\"u}tfi Kerem Senel and Maarten Bosma and Maarten Sap and Maartje Ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramirez-Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L Leavitt and Matthias Hagen and M{\'a}ty{\'a}s Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael Andrew Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Micha{\l} Sw{\k{e}}drowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan Andrew Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter W Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Mi{\l}kowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Rapha{\"e}l Milli{\`e}re and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan Le Bras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Russ Salakhutdinov and Ryan Andrew Chi and Seungjae Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel Stern Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima Shammie Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven Piantadosi and Stuart Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsunori Hashimoto and Te-Lin Wu and Th{\'e}o Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Venkatesh Ramasesh and vinay uday prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
  journal={Transactions on Machine Learning Research},
  url = {./files/srivastava2023beyond.pdf},
  year={2023},
  author+an = {227=highlight},
  keywords = {journal},
  index = {16}
}
@inproceedings{rule2023algorithmic,
  title = {Algorithmic foundations of mathematical development},
  author = {Rule, Joshua S. and Piantadosi, Steven T.},
  booktitle = {Proceedings of the {{Mathematical Cognition and Learning Society}}},
  year = {2023},
  note = {Symposium chair},
  author+an = {1=highlight},
  keywords = {misc},
  index = {17}
}
@article{ruleefficient,
  title = {{{Efficient}} learning of symbolic concepts via metaprogram search},
  author = {Rule, Joshua S. and Piantadosi, Steven T. and Tenenbaum, Joshua B.},
  status = {under review},
  author+an = {1=highlight},
  keywords = {journal},
  index = {18}
}
@article{piantadosicognitive,
  title = {How cognitive science (probably) figured out concepts},
  author = {Piantadosi, Steven T. and Muller, Dyana C. Y. and Rule, Joshua S. and Kaushik, Karthikeya and Gorenstein, Mark and Leib, Elena R. and Sanford, Emily},
  status = {under review},
  author+an = {3=highlight},
  keywords = {journal},
  index = {19}
}
@article{ruleend,
  title = {The end of radical concept nativism},
  author = {Rule, Joshua S. and Piantadosi, Steven T.},
  status = {under review},
  author+an = {1=highlight},
  keywords = {journal},
  index = {20}
}
@article{rulefun,
  title = {Fun isn't easy: {{Children}} choose more difficult options when ``playing for fun'' vs. ``trying to win''},
  author = {Rule, Joshua S. and Goddu, Mariel K. and Chu, Junyi and Pinter, Verity and Reagan, Emily Rose and Bonawitz, Elizabeth and Gopnik, Alison and Ullman, Tomer},
  status = {under review},
  author+an = {1=highlight},
  keywords = {journal},
  index = {21}
}
