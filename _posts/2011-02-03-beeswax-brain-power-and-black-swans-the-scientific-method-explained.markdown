---
author: joshrule
date: '2011-02-03 21:08:14'
layout: post
slug: beeswax-brain-power-and-black-swans-the-scientific-method-explained
status: publish
title: 'Beeswax, Brain Power, and Black Swans: The Scientific Method Explained '
wordpress_id: '107'
categories:
- science
---

![Black swans live in Australia - photo by 0ystercatcher and flickr.com][1]

Today's post is part of an ongoing series covering the fundamentals of
science. So far, the posts have been high-level. I haven't included a lot of
practical strategies or nifty tactics. Don't worry. The strategies are coming,
but it's critical we cover this stuff first. I want to think clearly when I'm
talking about such basic ideas as the definition of science or the ties
between science and bias. Otherwise, I'm just spewing ill-defined platitudes,
and neither of us have much chance of benefiting from this blog.

Throughout high school and my undergrad studies, a number of seemingly chance
experiences helped me form a much deeper understanding of the scientific
method than any formal presentation I've ever seen. I want to piece those
scraps into a coherent picture showing that the scientific method is basic to
great science precisely because it's an optimal tool for building good bias.

#### Three Steps to Science

Ultimately, the scientific method boils down to three key components:

*  **form some explanation**
*  **make a unique prediction**
*  **test its opposite**

Now, let's take a closer look.

#### Form Some Explanation

Technically, this step is satisfied by any imaginable explanation. I could
start explaining higher brain function in terms of beeswax production in
southern France, and it would meet the requirements of this step. All I need
is an explanation.

But, I don't recommend using beeswax to explain thoughts and personality,
because there's a difference between explanations and _good_ explanations. For
example, good explanations are justifiable in relation to already established
explanations. That is, good explanations build out of your biases. When prior
evidence has biased me to conclude that my thoughts result from incoming
stimuli, motor responses, and the electrical storm in my brain, remotely
located beeswax looks significantly less plausible. My biases establish prior
probabilities which influence the perceived likelihood of new explanations.
Unless you have incredibly strong evidence, I would just let the beeswax idea
die.

This first step is perhaps the hardest of the three, because [great
science][2] also demands significant creativity. You must find better
explanations than anyone's had before or radically confirm existing
explanations. Incremental improvements just won't cut it. Instead, you need
[deep domain knowledge][3] to understand what's already been tried, why those
attempts failed, what other possibilities may exist, and a host of supporting
details. Essentially, your brain needs to soak in a vat of information about
the question you're trying to answer[^1].

The good news is that developing good explanations isn't reserved for the
innate genius. It's a skill that can be learned, and one I'll talk about on
Monday.

#### Make A Unique Prediction

The next step is to find one of your explanation's unique predictions.
Explanations are models of how things work in reality. So, given some sort of
initial situation, we should be able to use your explanation to describe that
situation's outcome. For example, if I travel to visit the bee hives in
southern France, my explanation should be able to explain how the hives
actually affect my brain.

We also want our predictions to be unique to our model. Let's say I predict
that studying for three years while sitting among the beehives will make me
smarter than if I sat at home and watched paint dry. That's not a useful
prediction, because it could be explained either by the studying, the
beehives, or some strange interaction between them. In fact, this sort of
situation is exactly why controls and statistics are so important in modern
science. They help us isolate certain features of our models so we can make
unique predictions. It's also why Occam's Razor is so famous. It helps us cut
away unnecessary complications.

Now, if you can't make any predictions at all with your explanation, that
makes it worthless on two counts.

First, your explanation doesn't actually explain anything. The whole reason we
started modeling and explaining was to understand why things happened and how
we could arrange the future to our liking. Explanations that don't predict get
us absolutely no closer to those goals.

Second, if an explanation can't predict, it can't be tested. Remember,
[science][4], is about finding the _most_ likely explanations for things.
Without some handle to grab onto, we cannot make our theories more or less
likely. We have no way of testing them against reality. That's why [invisible
dragons][5] which leave the world totally unaffected by their presence rarely
make it into published science. The world could be filled with them, but we
just can't say anything useful about them.

The best explanations make scores of testable predictions for the same two
reasons we just discussed. Great explanations do a fantastic job of explaining
the past and predicting the future. And, they are also highly likely, because
their strong ties to reality make predictions that have been tested time and
time again. When was the last time you seriously doubted gravity?

#### Test Its Opposite

Lastly, we must test the opposite of our prediction. We must lug out the
equipment and actually see if French beeswax makes people smarter.
Unfortunately, scientists are often caricatured as doing just this last step.
One of the most common questions I'm asked when discussing my work is, "So,
what kind of experiments do you do?" While this question is fun to answer and
I really enjoy running experiments, it's just a small part of science.

Science is much like the 100m dash this way. Most of the work happens before
anyone lines up at the blocks. Runners spend years of their lives training for
a specific race. And, to be enamored with the race itself [ignores the great
pain and sacrifice][6] leading to the performance. The same is true of
science. Experiments are glamorous, but they are just a small part of a much
larger work. Experiments are the fallout of the heavy lifting that forms
explanations and predictions.

That doesn't make experiments unimportant any more than it makes the Olympic
final of the 100m dash unimportant. Without running the race, we don't know
for sure who is truly the fastest man alive. Without running the experiment,
we don't know for sure which explanation is truly the most likely. We cannot
ignore the results of an experiment any more than we can ignore that a runner
finished in first or last place. Final judgment relies exclusively on what can
be experienced in the real world, and the explanations of science, no matter
how coherent or elegant, must demonstrate their usefulness in reality.

So, tests are needed, but why should we test the opposite of our prediction?
Don't we want to speak to the likelihood of the actual prediction? We do, but
testing the prediction itself is a logical mistake known as [affirming the
consequent][7]. It's like saying: _If beeswax makes you smarter, then I'll eat
beeswax for breakfast. I eat beeswax for breakfast, therefore beeswax makes
you smarter._ Arguing this way just isn't logical.

Also, imagine I claim that all swans are white. I loudly proclaim to everyone
that I've never seen a [black swan][8], but I've seen hundreds of white swans
and therefore conclude there are no black swans. To test this theory, I search
for white swans, because that is what my theory predicts I can find. But, no
matter how many white swans I see, I cannot disprove the existence of a black
swan. The only way to establish my explanation of swan color is to search for
black swans. If I find one, then it's clear that not all swans are white. If I
don't find one after a thorough and sincere search, it's likely they don't
exist.

Remember, science is an inductive discipline. We can rarely prove our
explanations, because we have rarely seen all possible examples of what we're
explaining. But, a single true counterexample can fully disprove any
explanation[^2]. The theory of gravity could be shown wrong tomorrow.
Accordingly, science often moves forward by showing explanations to be more
likely than their opposites.

#### So, What?

Given all I've said, what's the big deal? Why make a fuss about the scientific
method? The big deal is that the scientific method revolutionizes our ability
to understand the universe. Without it, science struggled and was largely
based on the prejudices of the elite. Just think of the unusual and totally
fallacious statements made by people like Aristotle and medieval doctors
(bloodletting, anyone?).

With the scientific method, those unjustified prejudices can largely be
removed and replaced by more carefully considered biases. Consider the
advances we've experienced in physics alone since Newton's and Bacon's time.
Our ability to live well physically has dramatically improved in the last 400
years, and our ability to stave off the unknown has similarly increased.
That's a big deal.

But the biggest deal is the philosophical tool we've gained. Apart from the
physical benefits, the scientific method is also perhaps the optimal strategy
for doing science. Given the basic biases of science[^3], I'm claiming
there is probably no better process for forming and justifying explanations.
That makes the scientific method a guide to building good bias. It embodies a
few of our most fundamental biases in its very formulation, and shows us how
to find the others.

But, the basic scientific method I've given here leaves a lot unexplained. For
example, it doesn't tell you how to actually form good explanations. If that's
truly where so much of the work happens, you think someone could have taken a
little time to scratch out more detail on that front. On Monday, I'll start
looking more closely at exactly how good explanations can be formed.


[^1]: Grad school seems to serve as the first vat of this sort for a lot of people. That's probably one reason grad school seems so different from undergrad for a lot of people. In undergrad, you were occasionally splashed by a problem or two, but you never really soaked in one. In grad school, you've got to learn to [breathe while submerged][9] in this vat, and that takes some getting used to.
[^2]: I say _truly_ contrary because often, counterexamples can be explained away by methodology or other factors irrelevant to the explanation itself. In theory, this defense is good, but I'm not sure it's always used correctly.
[^3]: We've [started looking][10] at these biases already, and we'll continue to do so over the next few months.

[1]: /a/2011-02-03-beeswax-brain-power-and-black-swans-the-scientific-method-explained/black-swan.png (Black swans live in Australia - photo by 0ystercatcher and flickr.com)
[2]: http://joshrule.com/blog/an-answer-to-the-question-youve-all-been-asking/ (WOTS - An Answer to the Question You've All Been Asking)
[3]: http://joshrule.com/blog/trial-2-day-21-deep-domain-knowledge-and-deliberate-practice/ (WOTS - Trial 2: Day 21 - Deep Domain Knowledge and Deliberate Practice)
[4]: http://joshrule.com/blog/what-is-science/ (WOTS - What is Science?)
[5]: http://www.godlessgeeks.com/LINKS/Dragon.htm (Carl Sagan - The Dragon in My Garage)
[6]: http://chrisguillebeau.com/3x5/accomplishing-everything/ (Chris Guillebeau - Accomplishing Everything)
[7]: http://en.wikipedia.org/wiki/Affirming_the_consequent (Wikipedia - Affirming the Consequent)
[8]: http://en.wikipedia.org/wiki/Falsifiability (Wikipedia - Falsifiability)
[9]: http://en.wikipedia.org/wiki/Liquid_breathing (Wikipedia - Liquid Breathing)
[10]: http://joshrule.com/blog/science-needs-bias/ (WOTS - Science Needs Bias)
